apiVersion: v1
kind: Pod
metadata:
  name: mbart-finetune
  namespace: s85468
spec:
  restartPolicy: OnFailure
  containers:
  - name: mbart-finetune-container
    image: pytorch/pytorch:2.6.0-cuda12.4-cudnn9-runtime
    command: ["bash", "-c", "while true; do sleep 30; done"]
    resources:
      limits:
        nvidia.com/gpu: "1"
    volumeMounts:
    - name: fbusch-volume
      mountPath: /storage
  volumes:
  - name: fbusch-volume
    persistentVolumeClaim:
      claimName: fbusch-volume
  nodeSelector:
    gpu: v100
    #kubernetes.io/hostname: cl-worker29 ## ggf wieder auf v100 wechseln!

# Start the pod:
# kubectl apply -f mbart-finetune-pod.yml

# Exec into the pod:
# kubectl -n s85468 exec -it mbart-finetune -- bash
# cd /storage/text2gloss-finetune/mBART

# Delete the pod: 
# kubectl delete -f mbart-finetune-pod.yml

# Update mBART train script:
# kubectl cp /Users/frederikbusch/Developer/master-arbeit/text2gloss2pose/bht-cluster/mBART/train_mbart.py s85468/mbart-finetune:/storage/text2gloss-finetune/mBART/train_mbart.py

# Copy the results:
# kubectl cp s85468/mbart-finetune:/storage/text2gloss-finetune/mBART/evaluation_results_DEV.txt /Users/frederikbusch/Developer/master-arbeit/text2gloss2pose/bht-cluster/mbART/results/evaluation_results_DEV.txt
# kubectl cp s85468/mbart-finetune:/storage/text2gloss-finetune/mBART/evaluation_results_TEST.txt /Users/frederikbusch/Developer/master-arbeit/text2gloss2pose/bht-cluster/mBART/results/evaluation_results_TEST.txt
# kubectl cp s85468/mbart-finetune:/storage/text2gloss-finetune/mBART/final_model /Users/frederikbusch/Developer/master-arbeit/text2gloss2pose/bht-cluster/mBART/results/final_model

